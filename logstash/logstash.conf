input {
    beats{
        port => 5044
    }
    file {
        path => "/logstash_dir/*.json" # Surveiller les fichiers .json
        start_position => "beginning"  # Commencer depuis le début des fichiers
        sincedb_path => "/dev/null"    # Ignorer le suivi du positionnement du fichier pour éviter les problèmes potentiels
        codec => "json" # Lire chaque ligne comme un objet JSON
        mode => "tail"
    }
}

 filter {

#Supprimer les documents avec comme attribut "index" à la racine
    if [index] {
        drop{}
    }

# Ajouter un champ décade basé sur l'année
    ruby {
        code => '
            year = event.get("[fields][year]")
            if year
                decade = (year / 10).floor * 10
                event.set("[fields][decade]", "#{decade}s")
            end
        '
    }

#Convertir la durée en minutes
    if [fields][running_time_secs] {
        mutate {
            convert => {"[fields][running_time_secs]" => "integer"}
        }
        ruby {
            code => '
                secs = event.get("[fields][running_time_secs]")
                if secs
                    event.set("[fields][running_time_minutes]", secs / 60)
                end
            '
        }
        mutate {
            remove_field => ["[fields][running_time_secs]"]
        }
    }      

# Filtrer les films avec rating <5
    mutate {
        convert => { "[fields][rating]" => "float" }
    }
    if [fields][rating] and [fields][rating] < 5 {
        drop {}
    }
}    

output {
    stdout {
        codec => rubydebug
    }
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "movies"
        manage_template => true
        template => "/logstash_dir/mapping.json"
        template_name => "movies_template"
        document_id => "%{[id]}" # Lors de la réingestion d'un fichier, les documents seront écrasés (même ID) et donc pas dupliqués
    }
}